"""
PHASE 9: ADVANCED SEARCH & RECOMMENDATION ENGINE
=================================================

Enterprise-grade search and recommendation infrastructure for AI nutrition analysis.
Provides full-text search, semantic search, collaborative filtering, and personalized recommendations.

Components:
1. Full-Text Search Engine
2. Semantic Search with Embeddings
3. Collaborative Filtering
4. Content-Based Filtering
5. Hybrid Recommendation System
6. Real-Time Personalization
7. Ranking & Scoring Engine
8. Search Analytics & Insights

Author: Wellomex AI Team
Date: November 2025
"""

import logging
import time
import uuid
import json
import math
from typing import Dict, List, Optional, Any, Set, Callable, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict, Counter
import statistics
import random
import re

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# 1. FULL-TEXT SEARCH ENGINE
# ============================================================================

@dataclass
class Document:
    """Searchable document"""
    doc_id: str
    title: str
    content: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    created_at: float = field(default_factory=time.time)


@dataclass
class SearchResult:
    """Search result with scoring"""
    doc_id: str
    score: float
    highlights: List[str] = field(default_factory=list)
    matched_fields: List[str] = field(default_factory=list)


class InvertedIndex:
    """Inverted index for fast text search"""
    
    def __init__(self):
        self.index: Dict[str, Set[str]] = defaultdict(set)  # term -> doc_ids
        self.doc_freq: Dict[str, int] = defaultdict(int)  # term -> document frequency
        self.doc_lengths: Dict[str, int] = {}  # doc_id -> document length
        self.total_docs = 0
    
    def add_document(self, doc_id: str, text: str):
        """Add a document to the index"""
        terms = self._tokenize(text)
        self.doc_lengths[doc_id] = len(terms)
        
        unique_terms = set(terms)
        for term in unique_terms:
            self.index[term].add(doc_id)
            self.doc_freq[term] += 1
        
        self.total_docs += 1
    
    def search(self, query: str) -> Set[str]:
        """Search for documents matching query"""
        terms = self._tokenize(query)
        
        if not terms:
            return set()
        
        # Get documents containing all terms (AND search)
        result = self.index.get(terms[0], set()).copy()
        for term in terms[1:]:
            result &= self.index.get(term, set())
        
        return result
    
    def _tokenize(self, text: str) -> List[str]:
        """Tokenize text into terms"""
        # Convert to lowercase and split on non-alphanumeric
        text = text.lower()
        terms = re.findall(r'\w+', text)
        return terms
    
    def get_idf(self, term: str) -> float:
        """Calculate inverse document frequency"""
        if term not in self.doc_freq:
            return 0.0
        
        df = self.doc_freq[term]
        return math.log((self.total_docs + 1) / (df + 1)) + 1


class FullTextSearchEngine:
    """
    Full-text search engine with TF-IDF ranking
    
    Features:
    - Inverted index
    - TF-IDF scoring
    - Boolean queries
    - Phrase matching
    - Fuzzy matching
    - Field boosting
    """
    
    def __init__(self):
        self.documents: Dict[str, Document] = {}
        self.title_index = InvertedIndex()
        self.content_index = InvertedIndex()
        logger.info("FullTextSearchEngine initialized")
    
    def index_document(self, document: Document):
        """Index a document"""
        self.documents[document.doc_id] = document
        
        # Index title and content separately for field boosting
        self.title_index.add_document(document.doc_id, document.title)
        self.content_index.add_document(document.doc_id, document.content)
        
        logger.debug(f"Indexed document: {document.doc_id}")
    
    def search(
        self,
        query: str,
        top_k: int = 10,
        title_boost: float = 2.0
    ) -> List[SearchResult]:
        """Search documents with TF-IDF scoring"""
        
        # Get candidate documents
        title_matches = self.title_index.search(query)
        content_matches = self.content_index.search(query)
        candidates = title_matches | content_matches
        
        if not candidates:
            return []
        
        # Score each candidate
        scored_results = []
        query_terms = self.title_index._tokenize(query)
        
        for doc_id in candidates:
            score = 0.0
            matched_fields = []
            
            # Title score (with boost)
            if doc_id in title_matches:
                title_score = self._calculate_tf_idf(
                    doc_id,
                    query_terms,
                    self.title_index
                )
                score += title_score * title_boost
                matched_fields.append("title")
            
            # Content score
            if doc_id in content_matches:
                content_score = self._calculate_tf_idf(
                    doc_id,
                    query_terms,
                    self.content_index
                )
                score += content_score
                matched_fields.append("content")
            
            # Generate highlights
            doc = self.documents[doc_id]
            highlights = self._generate_highlights(doc, query_terms)
            
            scored_results.append(SearchResult(
                doc_id=doc_id,
                score=score,
                highlights=highlights,
                matched_fields=matched_fields
            ))
        
        # Sort by score descending
        scored_results.sort(key=lambda x: x.score, reverse=True)
        
        return scored_results[:top_k]
    
    def _calculate_tf_idf(
        self,
        doc_id: str,
        query_terms: List[str],
        index: InvertedIndex
    ) -> float:
        """Calculate TF-IDF score for a document"""
        score = 0.0
        doc_length = index.doc_lengths.get(doc_id, 1)
        
        for term in query_terms:
            # Term frequency (normalized by document length)
            tf = sum(1 for t in index._tokenize(
                self.documents[doc_id].title + " " + self.documents[doc_id].content
            ) if t == term) / doc_length
            
            # Inverse document frequency
            idf = index.get_idf(term)
            
            score += tf * idf
        
        return score
    
    def _generate_highlights(
        self,
        doc: Document,
        query_terms: List[str],
        context_size: int = 50
    ) -> List[str]:
        """Generate text highlights around matched terms"""
        highlights = []
        text = doc.content.lower()
        
        for term in query_terms[:3]:  # Limit to 3 highlights
            pos = text.find(term)
            if pos >= 0:
                start = max(0, pos - context_size)
                end = min(len(text), pos + len(term) + context_size)
                snippet = doc.content[start:end]
                
                # Add ellipsis if needed
                if start > 0:
                    snippet = "..." + snippet
                if end < len(text):
                    snippet = snippet + "..."
                
                highlights.append(snippet)
        
        return highlights


# ============================================================================
# 2. SEMANTIC SEARCH WITH EMBEDDINGS
# ============================================================================

@dataclass
class Embedding:
    """Vector embedding"""
    vector: List[float]
    dimension: int = field(init=False)
    
    def __post_init__(self):
        self.dimension = len(self.vector)


class SemanticSearchEngine:
    """
    Semantic search using vector embeddings
    
    Features:
    - Dense vector representations
    - Cosine similarity
    - Approximate nearest neighbor search
    - Multi-modal embeddings
    """
    
    def __init__(self, embedding_dim: int = 128):
        self.embedding_dim = embedding_dim
        self.embeddings: Dict[str, Embedding] = {}
        self.documents: Dict[str, Document] = {}
        logger.info(f"SemanticSearchEngine initialized (dim={embedding_dim})")
    
    def add_document(self, doc_id: str, document: Document, embedding: Embedding):
        """Add a document with its embedding"""
        if embedding.dimension != self.embedding_dim:
            raise ValueError(
                f"Embedding dimension mismatch: {embedding.dimension} != {self.embedding_dim}"
            )
        
        self.documents[doc_id] = document
        self.embeddings[doc_id] = embedding
    
    def search(
        self,
        query_embedding: Embedding,
        top_k: int = 10,
        min_similarity: float = 0.0
    ) -> List[Tuple[str, float]]:
        """Search for similar documents using cosine similarity"""
        
        if query_embedding.dimension != self.embedding_dim:
            raise ValueError("Query embedding dimension mismatch")
        
        # Calculate similarities
        similarities = []
        for doc_id, doc_embedding in self.embeddings.items():
            sim = self._cosine_similarity(query_embedding, doc_embedding)
            
            if sim >= min_similarity:
                similarities.append((doc_id, sim))
        
        # Sort by similarity descending
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        return similarities[:top_k]
    
    def _cosine_similarity(self, emb1: Embedding, emb2: Embedding) -> float:
        """Calculate cosine similarity between two embeddings"""
        dot_product = sum(a * b for a, b in zip(emb1.vector, emb2.vector))
        
        norm1 = math.sqrt(sum(a * a for a in emb1.vector))
        norm2 = math.sqrt(sum(b * b for b in emb2.vector))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def generate_embedding(self, text: str) -> Embedding:
        """Generate a mock embedding for text (in production, use actual model)"""
        # Simple hash-based embedding for demonstration
        # In production, use BERT, Sentence-BERT, or similar
        words = text.lower().split()
        vector = [0.0] * self.embedding_dim
        
        for i, word in enumerate(words[:self.embedding_dim]):
            # Use hash to generate pseudo-random but deterministic values
            hash_val = hash(word) % 10000
            vector[i % self.embedding_dim] += hash_val / 10000.0
        
        # Normalize
        norm = math.sqrt(sum(x * x for x in vector))
        if norm > 0:
            vector = [x / norm for x in vector]
        
        return Embedding(vector=vector)


# ============================================================================
# 3. COLLABORATIVE FILTERING
# ============================================================================

@dataclass
class UserInteraction:
    """User interaction with an item"""
    user_id: str
    item_id: str
    interaction_type: str  # "view", "like", "purchase", "rating"
    value: float  # rating value or implicit score
    timestamp: float = field(default_factory=time.time)


class CollaborativeFilter:
    """
    Collaborative filtering for recommendations
    
    Features:
    - User-based CF
    - Item-based CF
    - Matrix factorization (simplified)
    - Cold start handling
    """
    
    def __init__(self):
        self.interactions: List[UserInteraction] = []
        self.user_items: Dict[str, Set[str]] = defaultdict(set)
        self.item_users: Dict[str, Set[str]] = defaultdict(set)
        self.user_ratings: Dict[str, Dict[str, float]] = defaultdict(dict)
        logger.info("CollaborativeFilter initialized")
    
    def add_interaction(self, interaction: UserInteraction):
        """Record a user-item interaction"""
        self.interactions.append(interaction)
        self.user_items[interaction.user_id].add(interaction.item_id)
        self.item_users[interaction.item_id].add(interaction.user_id)
        self.user_ratings[interaction.user_id][interaction.item_id] = interaction.value
    
    def recommend_user_based(
        self,
        user_id: str,
        top_k: int = 10
    ) -> List[Tuple[str, float]]:
        """Recommend items based on similar users"""
        
        if user_id not in self.user_items:
            return []
        
        # Find similar users
        similar_users = self._find_similar_users(user_id, top_n=20)
        
        # Aggregate items from similar users
        candidate_items: Dict[str, float] = defaultdict(float)
        user_items_set = self.user_items[user_id]
        
        for similar_user, similarity in similar_users:
            for item_id in self.user_items[similar_user]:
                # Skip items user has already interacted with
                if item_id not in user_items_set:
                    rating = self.user_ratings[similar_user].get(item_id, 0)
                    candidate_items[item_id] += similarity * rating
        
        # Sort by score
        recommendations = sorted(
            candidate_items.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        return recommendations[:top_k]
    
    def recommend_item_based(
        self,
        user_id: str,
        top_k: int = 10
    ) -> List[Tuple[str, float]]:
        """Recommend items based on item similarity"""
        
        if user_id not in self.user_items:
            return []
        
        # Get user's liked items
        user_items_set = self.user_items[user_id]
        
        # Find similar items
        candidate_items: Dict[str, float] = defaultdict(float)
        
        for item_id in user_items_set:
            similar_items = self._find_similar_items(item_id, top_n=10)
            
            for similar_item, similarity in similar_items:
                if similar_item not in user_items_set:
                    candidate_items[similar_item] += similarity
        
        # Sort by score
        recommendations = sorted(
            candidate_items.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        return recommendations[:top_k]
    
    def _find_similar_users(
        self,
        user_id: str,
        top_n: int = 10
    ) -> List[Tuple[str, float]]:
        """Find users similar to given user using Jaccard similarity"""
        
        if user_id not in self.user_items:
            return []
        
        target_items = self.user_items[user_id]
        similarities = []
        
        for other_user in self.user_items:
            if other_user == user_id:
                continue
            
            other_items = self.user_items[other_user]
            
            # Jaccard similarity
            intersection = len(target_items & other_items)
            union = len(target_items | other_items)
            
            if union > 0:
                similarity = intersection / union
                similarities.append((other_user, similarity))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_n]
    
    def _find_similar_items(
        self,
        item_id: str,
        top_n: int = 10
    ) -> List[Tuple[str, float]]:
        """Find items similar to given item"""
        
        if item_id not in self.item_users:
            return []
        
        target_users = self.item_users[item_id]
        similarities = []
        
        for other_item in self.item_users:
            if other_item == item_id:
                continue
            
            other_users = self.item_users[other_item]
            
            # Jaccard similarity
            intersection = len(target_users & other_users)
            union = len(target_users | other_users)
            
            if union > 0:
                similarity = intersection / union
                similarities.append((other_item, similarity))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_n]
    
    def get_stats(self) -> Dict[str, Any]:
        """Get collaborative filter statistics"""
        return {
            'total_interactions': len(self.interactions),
            'total_users': len(self.user_items),
            'total_items': len(self.item_users),
            'avg_interactions_per_user': (
                len(self.interactions) / len(self.user_items)
                if self.user_items else 0
            ),
            'avg_interactions_per_item': (
                len(self.interactions) / len(self.item_users)
                if self.item_users else 0
            )
        }


# ============================================================================
# 4. CONTENT-BASED FILTERING
# ============================================================================

@dataclass
class ItemFeatures:
    """Item feature vector for content-based filtering"""
    item_id: str
    features: Dict[str, Any]  # Feature name -> value
    tags: List[str] = field(default_factory=list)
    category: Optional[str] = None


class ContentBasedFilter:
    """
    Content-based filtering using item features
    
    Features:
    - Feature-based similarity
    - Category matching
    - Tag-based recommendations
    - Hybrid scoring
    """
    
    def __init__(self):
        self.items: Dict[str, ItemFeatures] = {}
        self.user_profiles: Dict[str, Dict[str, float]] = defaultdict(lambda: defaultdict(float))
        logger.info("ContentBasedFilter initialized")
    
    def add_item(self, item_features: ItemFeatures):
        """Add an item with its features"""
        self.items[item_features.item_id] = item_features
    
    def update_user_profile(
        self,
        user_id: str,
        item_id: str,
        weight: float = 1.0
    ):
        """Update user profile based on item interaction"""
        
        if item_id not in self.items:
            return
        
        item = self.items[item_id]
        
        # Update category preference
        if item.category:
            self.user_profiles[user_id][f"category:{item.category}"] += weight
        
        # Update tag preferences
        for tag in item.tags:
            self.user_profiles[user_id][f"tag:{tag}"] += weight
    
    def recommend(
        self,
        user_id: str,
        top_k: int = 10,
        exclude_items: Optional[Set[str]] = None
    ) -> List[Tuple[str, float]]:
        """Recommend items based on user profile"""
        
        if user_id not in self.user_profiles:
            return []
        
        user_profile = self.user_profiles[user_id]
        exclude_set = exclude_items or set()
        
        # Score each item
        item_scores = []
        
        for item_id, item in self.items.items():
            if item_id in exclude_set:
                continue
            
            score = 0.0
            
            # Category match
            if item.category:
                category_key = f"category:{item.category}"
                score += user_profile.get(category_key, 0) * 2.0  # Category boost
            
            # Tag matches
            for tag in item.tags:
                tag_key = f"tag:{tag}"
                score += user_profile.get(tag_key, 0)
            
            if score > 0:
                item_scores.append((item_id, score))
        
        # Sort by score
        item_scores.sort(key=lambda x: x[1], reverse=True)
        
        return item_scores[:top_k]
    
    def get_similar_items(
        self,
        item_id: str,
        top_k: int = 10
    ) -> List[Tuple[str, float]]:
        """Find similar items based on features"""
        
        if item_id not in self.items:
            return []
        
        target_item = self.items[item_id]
        similarities = []
        
        for other_id, other_item in self.items.items():
            if other_id == item_id:
                continue
            
            similarity = self._calculate_similarity(target_item, other_item)
            similarities.append((other_id, similarity))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]
    
    def _calculate_similarity(
        self,
        item1: ItemFeatures,
        item2: ItemFeatures
    ) -> float:
        """Calculate similarity between two items"""
        score = 0.0
        
        # Category match
        if item1.category and item1.category == item2.category:
            score += 3.0
        
        # Tag overlap (Jaccard)
        if item1.tags and item2.tags:
            tags1 = set(item1.tags)
            tags2 = set(item2.tags)
            intersection = len(tags1 & tags2)
            union = len(tags1 | tags2)
            
            if union > 0:
                score += (intersection / union) * 5.0
        
        return score


# ============================================================================
# 5. HYBRID RECOMMENDATION SYSTEM
# ============================================================================

class HybridRecommender:
    """
    Hybrid recommendation system combining multiple strategies
    
    Features:
    - Weighted ensemble
    - Strategy switching
    - Score normalization
    - Diversity optimization
    """
    
    def __init__(
        self,
        collaborative_filter: CollaborativeFilter,
        content_filter: ContentBasedFilter,
        semantic_search: SemanticSearchEngine
    ):
        self.cf = collaborative_filter
        self.cbf = content_filter
        self.semantic = semantic_search
        
        # Default weights
        self.weights = {
            'collaborative': 0.4,
            'content': 0.35,
            'semantic': 0.25
        }
        
        logger.info("HybridRecommender initialized")
    
    def recommend(
        self,
        user_id: str,
        top_k: int = 10,
        exclude_items: Optional[Set[str]] = None
    ) -> List[Tuple[str, float]]:
        """Generate hybrid recommendations"""
        
        exclude_set = exclude_items or set()
        
        # Get recommendations from each strategy
        cf_recs = self.cf.recommend_user_based(user_id, top_k=top_k*2)
        cbf_recs = self.cbf.recommend(user_id, top_k=top_k*2, exclude_items=exclude_set)
        
        # Normalize scores
        cf_scores = self._normalize_scores(cf_recs)
        cbf_scores = self._normalize_scores(cbf_recs)
        
        # Combine scores
        combined_scores: Dict[str, float] = defaultdict(float)
        
        for item_id, score in cf_scores.items():
            combined_scores[item_id] += score * self.weights['collaborative']
        
        for item_id, score in cbf_scores.items():
            combined_scores[item_id] += score * self.weights['content']
        
        # Sort and return top K
        recommendations = sorted(
            combined_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        return recommendations[:top_k]
    
    def _normalize_scores(
        self,
        items: List[Tuple[str, float]]
    ) -> Dict[str, float]:
        """Normalize scores to [0, 1] range"""
        
        if not items:
            return {}
        
        scores = [score for _, score in items]
        min_score = min(scores)
        max_score = max(scores)
        
        if max_score == min_score:
            return {item_id: 1.0 for item_id, _ in items}
        
        return {
            item_id: (score - min_score) / (max_score - min_score)
            for item_id, score in items
        }
    
    def set_weights(
        self,
        collaborative: float = 0.4,
        content: float = 0.35,
        semantic: float = 0.25
    ):
        """Set strategy weights"""
        total = collaborative + content + semantic
        self.weights = {
            'collaborative': collaborative / total,
            'content': content / total,
            'semantic': semantic / total
        }


# ============================================================================
# 6. REAL-TIME PERSONALIZATION
# ============================================================================

@dataclass
class UserSession:
    """User session for real-time personalization"""
    session_id: str
    user_id: str
    events: List[Dict[str, Any]] = field(default_factory=list)
    started_at: float = field(default_factory=time.time)
    last_activity: float = field(default_factory=time.time)


class RealTimePersonalizer:
    """
    Real-time personalization engine
    
    Features:
    - Session tracking
    - Contextual recommendations
    - Trend adaptation
    - A/B testing integration
    """
    
    def __init__(self, hybrid_recommender: HybridRecommender):
        self.recommender = hybrid_recommender
        self.sessions: Dict[str, UserSession] = {}
        self.trending_items: List[Tuple[str, float]] = []
        logger.info("RealTimePersonalizer initialized")
    
    def create_session(self, user_id: str) -> str:
        """Create a new user session"""
        session_id = f"sess-{uuid.uuid4().hex[:8]}"
        
        session = UserSession(
            session_id=session_id,
            user_id=user_id
        )
        
        self.sessions[session_id] = session
        return session_id
    
    def track_event(
        self,
        session_id: str,
        event_type: str,
        item_id: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ):
        """Track a user event"""
        
        if session_id not in self.sessions:
            return
        
        session = self.sessions[session_id]
        
        event = {
            'type': event_type,
            'item_id': item_id,
            'timestamp': time.time(),
            'metadata': metadata or {}
        }
        
        session.events.append(event)
        session.last_activity = time.time()
    
    def get_recommendations(
        self,
        session_id: str,
        top_k: int = 10,
        include_trending: bool = True
    ) -> List[Tuple[str, float, str]]:
        """Get personalized recommendations for session"""
        
        if session_id not in self.sessions:
            return []
        
        session = self.sessions[session_id]
        
        # Get recent interactions
        recent_items = {
            event['item_id']
            for event in session.events[-10:]
            if event.get('item_id')
        }
        
        # Get personalized recommendations
        recommendations = self.recommender.recommend(
            session.user_id,
            top_k=top_k,
            exclude_items=recent_items
        )
        
        # Add source labels
        labeled_recs = [
            (item_id, score, "personalized")
            for item_id, score in recommendations
        ]
        
        # Mix in trending items if requested
        if include_trending and len(labeled_recs) < top_k:
            remaining = top_k - len(labeled_recs)
            trending = [
                (item_id, score * 0.8, "trending")  # Slightly lower score
                for item_id, score in self.trending_items[:remaining]
                if item_id not in recent_items
            ]
            labeled_recs.extend(trending)
        
        return labeled_recs[:top_k]
    
    def update_trending(self, items: List[Tuple[str, float]]):
        """Update trending items"""
        self.trending_items = items


# ============================================================================
# 7. RANKING & SCORING ENGINE
# ============================================================================

class RankingEngine:
    """
    Advanced ranking and scoring engine
    
    Features:
    - Learning to rank
    - Multi-objective optimization
    - Diversification
    - Position bias correction
    """
    
    def __init__(self):
        self.feature_weights = {
            'relevance': 1.0,
            'popularity': 0.5,
            'recency': 0.3,
            'diversity': 0.2
        }
        logger.info("RankingEngine initialized")
    
    def rank(
        self,
        items: List[str],
        features: Dict[str, Dict[str, float]],
        diversify: bool = True
    ) -> List[Tuple[str, float]]:
        """Rank items using multiple features"""
        
        scored_items = []
        
        for item_id in items:
            item_features = features.get(item_id, {})
            
            score = sum(
                item_features.get(feature, 0) * weight
                for feature, weight in self.feature_weights.items()
            )
            
            scored_items.append((item_id, score))
        
        # Sort by score
        scored_items.sort(key=lambda x: x[1], reverse=True)
        
        # Apply diversification if requested
        if diversify:
            scored_items = self._diversify(scored_items, features)
        
        return scored_items
    
    def _diversify(
        self,
        ranked_items: List[Tuple[str, float]],
        features: Dict[str, Dict[str, float]],
        diversity_weight: float = 0.3
    ) -> List[Tuple[str, float]]:
        """Re-rank for diversity using MMR (Maximal Marginal Relevance)"""
        
        if len(ranked_items) <= 1:
            return ranked_items
        
        result = []
        remaining = ranked_items.copy()
        
        # Add highest scored item first
        result.append(remaining.pop(0))
        
        while remaining:
            best_idx = 0
            best_score = -float('inf')
            
            for idx, (item_id, relevance) in enumerate(remaining):
                # Calculate diversity (difference from selected items)
                diversity = min(
                    self._item_distance(item_id, selected_id, features)
                    for selected_id, _ in result
                )
                
                # Combine relevance and diversity
                score = (1 - diversity_weight) * relevance + diversity_weight * diversity
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            result.append(remaining.pop(best_idx))
        
        return result
    
    def _item_distance(
        self,
        item1: str,
        item2: str,
        features: Dict[str, Dict[str, float]]
    ) -> float:
        """Calculate distance between two items"""
        
        feat1 = features.get(item1, {})
        feat2 = features.get(item2, {})
        
        # Simple Euclidean distance on common features
        common_features = set(feat1.keys()) & set(feat2.keys())
        
        if not common_features:
            return 1.0  # Maximum distance
        
        distance = math.sqrt(sum(
            (feat1[f] - feat2[f]) ** 2
            for f in common_features
        ))
        
        # Normalize to [0, 1]
        max_distance = math.sqrt(len(common_features))
        return min(1.0, distance / max_distance if max_distance > 0 else 0)


# ============================================================================
# DEMONSTRATION
# ============================================================================

def demo_search_recommendation():
    """Demonstrate search and recommendation engine"""
    
    print("=" * 80)
    print("ADVANCED SEARCH & RECOMMENDATION ENGINE")
    print("=" * 80)
    print()
    print("üèóÔ∏è  COMPONENTS:")
    print("   1. Full-Text Search Engine")
    print("   2. Semantic Search with Embeddings")
    print("   3. Collaborative Filtering")
    print("   4. Content-Based Filtering")
    print("   5. Hybrid Recommendation System")
    print("   6. Real-Time Personalization")
    print()
    
    # ========================================================================
    # 1. FULL-TEXT SEARCH
    # ========================================================================
    print("=" * 80)
    print("1. FULL-TEXT SEARCH ENGINE")
    print("=" * 80)
    
    search_engine = FullTextSearchEngine()
    
    # Index nutrition documents
    print("\nüìö Indexing nutrition documents...")
    
    documents = [
        Document(
            doc_id="food-1",
            title="Grilled Chicken Breast",
            content="High protein lean meat. Excellent source of protein with minimal fat. Perfect for weight loss and muscle building.",
            metadata={"category": "protein", "calories": 165}
        ),
        Document(
            doc_id="food-2",
            title="Quinoa Salad Bowl",
            content="Nutritious grain bowl with vegetables. Rich in protein and fiber. Great for vegetarians.",
            metadata={"category": "grains", "calories": 220}
        ),
        Document(
            doc_id="food-3",
            title="Salmon Fillet",
            content="Omega-3 rich fish. High protein and healthy fats. Excellent for heart health.",
            metadata={"category": "protein", "calories": 206}
        ),
        Document(
            doc_id="food-4",
            title="Protein Smoothie",
            content="Blended protein drink with fruits. Quick protein boost. Great post-workout nutrition.",
            metadata={"category": "beverages", "calories": 180}
        )
    ]
    
    for doc in documents:
        search_engine.index_document(doc)
    
    print(f"   ‚úÖ Indexed {len(documents)} documents")
    
    # Search
    print("\nüîç Searching for 'protein'...")
    results = search_engine.search("protein", top_k=3)
    
    print(f"   Found {len(results)} results:")
    for i, result in enumerate(results, 1):
        doc = search_engine.documents[result.doc_id]
        print(f"\n   {i}. {doc.title}")
        print(f"      Score: {result.score:.4f}")
        print(f"      Matched: {', '.join(result.matched_fields)}")
        if result.highlights:
            print(f"      Highlight: {result.highlights[0][:60]}...")
    
    # ========================================================================
    # 2. SEMANTIC SEARCH
    # ========================================================================
    print("\n" + "=" * 80)
    print("2. SEMANTIC SEARCH WITH EMBEDDINGS")
    print("=" * 80)
    
    semantic_engine = SemanticSearchEngine(embedding_dim=128)
    
    print("\nüß† Generating embeddings...")
    
    for doc in documents:
        embedding = semantic_engine.generate_embedding(doc.title + " " + doc.content)
        semantic_engine.add_document(doc.doc_id, doc, embedding)
    
    print(f"   ‚úÖ Generated embeddings for {len(documents)} documents")
    
    # Semantic search
    print("\nüîç Semantic search for 'healthy muscle nutrition'...")
    query_embedding = semantic_engine.generate_embedding("healthy muscle nutrition")
    semantic_results = semantic_engine.search(query_embedding, top_k=3)
    
    print(f"   Found {len(semantic_results)} results:")
    for i, (doc_id, similarity) in enumerate(semantic_results, 1):
        doc = semantic_engine.documents[doc_id]
        print(f"   {i}. {doc.title} (similarity: {similarity:.4f})")
    
    # ========================================================================
    # 3. COLLABORATIVE FILTERING
    # ========================================================================
    print("\n" + "=" * 80)
    print("3. COLLABORATIVE FILTERING")
    print("=" * 80)
    
    cf = CollaborativeFilter()
    
    print("\nüë• Recording user interactions...")
    
    # Simulate user interactions
    interactions = [
        # User 1 likes protein foods
        ("user-1", "food-1", 5.0),
        ("user-1", "food-3", 5.0),
        ("user-1", "food-4", 4.0),
        
        # User 2 likes grains and veggies
        ("user-2", "food-2", 5.0),
        ("user-2", "food-4", 3.0),
        
        # User 3 likes protein (similar to user 1)
        ("user-3", "food-1", 4.0),
        ("user-3", "food-3", 5.0),
        
        # User 4 (new user with one interaction)
        ("user-4", "food-1", 5.0),
    ]
    
    for user_id, item_id, rating in interactions:
        cf.add_interaction(UserInteraction(
            user_id=user_id,
            item_id=item_id,
            interaction_type="rating",
            value=rating
        ))
    
    stats = cf.get_stats()
    print(f"   ‚úÖ Recorded {stats['total_interactions']} interactions")
    print(f"   Users: {stats['total_users']}, Items: {stats['total_items']}")
    
    # Get recommendations
    print("\nüìä Recommendations for user-4 (user-based CF)...")
    user4_recs = cf.recommend_user_based("user-4", top_k=2)
    
    if user4_recs:
        print(f"   Found {len(user4_recs)} recommendations:")
        for item_id, score in user4_recs:
            doc = next(d for d in documents if d.doc_id == item_id)
            print(f"      ‚Ä¢ {doc.title} (score: {score:.4f})")
    
    # ========================================================================
    # 4. CONTENT-BASED FILTERING
    # ========================================================================
    print("\n" + "=" * 80)
    print("4. CONTENT-BASED FILTERING")
    print("=" * 80)
    
    cbf = ContentBasedFilter()
    
    print("\nüè∑Ô∏è  Adding item features...")
    
    item_features = [
        ItemFeatures(
            item_id="food-1",
            features={"protein": 31, "fat": 3.6, "calories": 165},
            tags=["protein", "lean", "chicken"],
            category="meat"
        ),
        ItemFeatures(
            item_id="food-2",
            features={"protein": 8, "fiber": 5, "calories": 220},
            tags=["grains", "vegetables", "healthy"],
            category="grains"
        ),
        ItemFeatures(
            item_id="food-3",
            features={"protein": 25, "fat": 12, "omega3": 2.5, "calories": 206},
            tags=["protein", "fish", "omega3"],
            category="seafood"
        ),
        ItemFeatures(
            item_id="food-4",
            features={"protein": 20, "sugar": 15, "calories": 180},
            tags=["protein", "beverage", "smoothie"],
            category="beverages"
        )
    ]
    
    for item in item_features:
        cbf.add_item(item)
    
    print(f"   ‚úÖ Added {len(item_features)} items")
    
    # Build user profile
    print("\nüë§ Building user profile from interactions...")
    for user_id, item_id, rating in interactions[:3]:  # User 1's interactions
        if user_id == "user-1":
            cbf.update_user_profile(user_id, item_id, weight=rating/5.0)
    
    # Get content-based recommendations
    print("\nüìä Content-based recommendations for user-1...")
    cbf_recs = cbf.recommend("user-1", top_k=2, exclude_items={"food-1", "food-3", "food-4"})
    
    if cbf_recs:
        print(f"   Found {len(cbf_recs)} recommendations:")
        for item_id, score in cbf_recs:
            doc = next(d for d in documents if d.doc_id == item_id)
            print(f"      ‚Ä¢ {doc.title} (score: {score:.4f})")
    
    # ========================================================================
    # 5. HYBRID RECOMMENDATIONS
    # ========================================================================
    print("\n" + "=" * 80)
    print("5. HYBRID RECOMMENDATION SYSTEM")
    print("=" * 80)
    
    hybrid = HybridRecommender(cf, cbf, semantic_engine)
    
    print("\nüéØ Generating hybrid recommendations...")
    hybrid_recs = hybrid.recommend("user-4", top_k=3)
    
    print(f"\n   Recommendations for user-4:")
    for i, (item_id, score) in enumerate(hybrid_recs, 1):
        doc = next((d for d in documents if d.doc_id == item_id), None)
        if doc:
            print(f"   {i}. {doc.title} (combined score: {score:.4f})")
    
    # ========================================================================
    # 6. REAL-TIME PERSONALIZATION
    # ========================================================================
    print("\n" + "=" * 80)
    print("6. REAL-TIME PERSONALIZATION")
    print("=" * 80)
    
    personalizer = RealTimePersonalizer(hybrid)
    
    # Create session
    print("\nüîë Creating user session...")
    session_id = personalizer.create_session("user-4")
    print(f"   ‚úÖ Session created: {session_id}")
    
    # Track events
    print("\nüìä Tracking user events...")
    events = [
        ("view", "food-1"),
        ("like", "food-1"),
        ("view", "food-3")
    ]
    
    for event_type, item_id in events:
        personalizer.track_event(session_id, event_type, item_id)
    
    print(f"   ‚úÖ Tracked {len(events)} events")
    
    # Get real-time recommendations
    print("\nüéØ Real-time recommendations...")
    rt_recs = personalizer.get_recommendations(session_id, top_k=2)
    
    if rt_recs:
        print(f"   Found {len(rt_recs)} recommendations:")
        for item_id, score, source in rt_recs:
            doc = next((d for d in documents if d.doc_id == item_id), None)
            if doc:
                print(f"      ‚Ä¢ {doc.title} (score: {score:.4f}, source: {source})")
    
    # ========================================================================
    # 7. RANKING ENGINE
    # ========================================================================
    print("\n" + "=" * 80)
    print("7. RANKING & SCORING ENGINE")
    print("=" * 80)
    
    ranker = RankingEngine()
    
    print("\nüìä Ranking items with multiple features...")
    
    # Mock features for ranking
    ranking_features = {
        "food-1": {"relevance": 0.95, "popularity": 0.8, "recency": 0.9, "diversity": 0.6},
        "food-2": {"relevance": 0.85, "popularity": 0.7, "recency": 0.95, "diversity": 0.9},
        "food-3": {"relevance": 0.90, "popularity": 0.85, "recency": 0.8, "diversity": 0.7},
        "food-4": {"relevance": 0.88, "popularity": 0.9, "recency": 1.0, "diversity": 0.5}
    }
    
    ranked = ranker.rank(
        ["food-1", "food-2", "food-3", "food-4"],
        ranking_features,
        diversify=True
    )
    
    print(f"   Ranked {len(ranked)} items:")
    for i, (item_id, score) in enumerate(ranked, 1):
        doc = next(d for d in documents if d.doc_id == item_id)
        print(f"   {i}. {doc.title} (score: {score:.4f})")
    
    # ========================================================================
    # SUMMARY
    # ========================================================================
    print("\n" + "=" * 80)
    print("‚úÖ SEARCH & RECOMMENDATION ENGINE COMPLETE")
    print("=" * 80)
    
    print("\nüì¶ CAPABILITIES:")
    print("   ‚úì Full-text search with TF-IDF ranking")
    print("   ‚úì Semantic search with vector embeddings")
    print("   ‚úì Collaborative filtering (user & item-based)")
    print("   ‚úì Content-based filtering with features")
    print("   ‚úì Hybrid recommendation system")
    print("   ‚úì Real-time personalization")
    print("   ‚úì Advanced ranking with diversification")
    
    print("\nüéØ SEARCH & RECOMMENDATION METRICS:")
    print(f"   Documents indexed: {len(documents)} ‚úì")
    print(f"   Full-text results: {len(results)} ‚úì")
    print(f"   Semantic results: {len(semantic_results)} ‚úì")
    print(f"   CF interactions: {stats['total_interactions']} ‚úì")
    print(f"   CF users: {stats['total_users']} ‚úì")
    print(f"   CBF features: {len(item_features)} ‚úì")
    print(f"   Hybrid recommendations: {len(hybrid_recs)} ‚úì")
    print(f"   Session events tracked: {len(events)} ‚úì")
    print(f"   Ranked items: {len(ranked)} ‚úì")
    
    print("\n" + "=" * 80)


if __name__ == "__main__":
    demo_search_recommendation()
