"""
LLM-Based Disease Profile Generator
====================================

Generates disease nutritional profiles dynamically using GPT-4 or other LLMs
instead of hardcoded data. This allows for:
- Up-to-date medical recommendations
- Personalized variations based on patient context
- Easy updates without code changes
- Multi-language support
"""

import os
import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
import time


@dataclass
class NutritionalGuideline:
    """Nutritional guideline from LLM"""
    nutrient: str
    target: str
    unit: str
    priority: str
    reasoning: str


@dataclass
class FoodRestriction:
    """Food restriction from LLM"""
    food_item: str
    severity: str
    reason: str
    alternatives: List[str]


@dataclass
class LLMDiseaseProfile:
    """Disease profile generated by LLM"""
    disease_id: str
    name: str
    icd10_codes: List[str]
    category: str
    nutritional_guidelines: List[NutritionalGuideline]
    food_restrictions: List[FoodRestriction]
    recommended_foods: List[str]
    meal_timing: str
    portion_control: str
    evidence_sources: List[str]
    last_updated: str
    llm_model: str


class LLMDiseaseProfileGenerator:
    """Generates disease profiles using LLM"""
    
    def __init__(self, api_key: Optional[str] = None, provider: str = "openai", model: str = "gpt-4-turbo-preview"):
        """
        Initialize LLM disease profile generator
        
        Args:
            api_key: API key for LLM provider
            provider: LLM provider (openai, azure, anthropic)
            model: Model to use
        """
        self.provider = provider
        self.model = model
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.client = None
        self.total_tokens = 0
        
        self._initialize_client()
    
    def _initialize_client(self):
        """Initialize LLM client"""
        if not self.api_key:
            print("‚ö†Ô∏è No API key found. LLM features disabled.")
            print("Set OPENAI_API_KEY environment variable to enable.")
            return
        
        try:
            if self.provider == "openai":
                import openai
                self.client = openai.OpenAI(api_key=self.api_key)
            elif self.provider == "azure":
                import openai
                self.client = openai.AzureOpenAI(
                    api_key=self.api_key,
                    api_version=os.getenv("AZURE_API_VERSION", "2024-02-15-preview"),
                    azure_endpoint=os.getenv("AZURE_ENDPOINT")
                )
            elif self.provider == "anthropic":
                import anthropic
                self.client = anthropic.Anthropic(api_key=self.api_key)
            
            print(f"‚úÖ LLM client initialized: {self.provider}/{self.model}")
        except ImportError as e:
            print(f"‚ö†Ô∏è LLM library not installed: {e}")
            print(f"Install with: pip install openai anthropic")
        except Exception as e:
            print(f"‚ùå Failed to initialize LLM client: {e}")
    
    def generate_disease_profile(self, 
                                 disease_name: str,
                                 icd10_code: str = None,
                                 category: str = None,
                                 patient_context: Dict[str, Any] = None) -> Optional[LLMDiseaseProfile]:
        """
        Generate complete disease nutritional profile using LLM
        
        Args:
            disease_name: Name of the disease
            icd10_code: ICD-10 code if known
            category: Disease category
            patient_context: Optional patient-specific context (age, gender, severity, etc.)
        
        Returns:
            LLMDiseaseProfile or None if generation fails
        """
        if not self.client:
            print("‚ùå LLM client not initialized")
            return None
        
        # Build the prompt
        prompt = self._build_profile_generation_prompt(disease_name, icd10_code, category, patient_context)
        
        try:
            # Call LLM
            if self.provider in ["openai", "azure"]:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": self._get_system_prompt()},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,  # Lower temperature for more consistent medical advice
                    response_format={"type": "json_object"}
                )
                
                content = response.choices[0].message.content
                self.total_tokens += response.usage.total_tokens
                
            elif self.provider == "anthropic":
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=4096,
                    temperature=0.3,
                    messages=[
                        {"role": "user", "content": prompt}
                    ]
                )
                
                content = response.content[0].text
                self.total_tokens += response.usage.input_tokens + response.usage.output_tokens
            
            # Parse response
            profile_data = json.loads(content)
            
            # Convert to dataclass
            profile = self._parse_llm_response(profile_data, disease_name)
            
            print(f"‚úÖ Generated profile for {disease_name}")
            return profile
            
        except Exception as e:
            print(f"‚ùå Failed to generate profile for {disease_name}: {e}")
            return None
    
    def _get_system_prompt(self) -> str:
        """Get system prompt for LLM"""
        return """You are an expert clinical nutritionist and dietitian with deep knowledge of:
- Medical nutrition therapy for various diseases
- Evidence-based dietary guidelines from WHO, ADA, AHA, and other authorities
- ICD-10 disease classification
- Macronutrient and micronutrient requirements
- Food-drug interactions
- Cultural and dietary preferences

Your task is to generate comprehensive, evidence-based nutritional profiles for diseases.

IMPORTANT REQUIREMENTS:
1. All recommendations must be based on current medical evidence
2. Include specific, measurable targets (not vague advice)
3. Prioritize safety - critical restrictions should prevent harm
4. Consider common comorbidities
5. Provide practical, culturally-appropriate food recommendations
6. Cite evidence sources when possible

OUTPUT FORMAT:
Return ONLY valid JSON with this exact structure (no markdown, no explanations):
{
  "disease_id": "lowercase_underscore_format",
  "name": "Official Disease Name",
  "icd10_codes": ["A00.0"],
  "category": "cardiovascular|metabolic|digestive|respiratory|etc",
  "nutritional_guidelines": [
    {
      "nutrient": "nutrient_name",
      "target": "value_or_range",
      "unit": "g|mg|%|etc",
      "priority": "critical|high|medium|low",
      "reasoning": "brief_scientific_rationale"
    }
  ],
  "food_restrictions": [
    {
      "food_item": "specific_food_or_category",
      "severity": "critical|high|medium|low",
      "reason": "why_to_avoid",
      "alternatives": ["alternative1", "alternative2"]
    }
  ],
  "recommended_foods": ["food1", "food2", ...],
  "meal_timing": "timing_recommendations",
  "portion_control": "portion_guidance",
  "evidence_sources": ["source1", "source2"]
}"""
    
    def _build_profile_generation_prompt(self, 
                                         disease_name: str,
                                         icd10_code: Optional[str],
                                         category: Optional[str],
                                         patient_context: Optional[Dict]) -> str:
        """Build the user prompt for profile generation"""
        
        prompt = f"Generate a comprehensive nutritional profile for: {disease_name}\n\n"
        
        if icd10_code:
            prompt += f"ICD-10 Code: {icd10_code}\n"
        
        if category:
            prompt += f"Category: {category}\n"
        
        if patient_context:
            prompt += "\nPatient Context:\n"
            for key, value in patient_context.items():
                prompt += f"- {key}: {value}\n"
        
        prompt += """
Generate a complete nutritional profile including:

1. NUTRITIONAL GUIDELINES (10-15 guidelines):
   - Macronutrients (carbs, protein, fat, fiber)
   - Key micronutrients (vitamins, minerals)
   - Fluid intake
   - Specific targets with units
   - Priority levels (critical/high/medium/low)

2. FOOD RESTRICTIONS (8-12 restrictions):
   - Foods to avoid or limit
   - Severity levels (critical = must avoid, high = strongly limit, medium = limit, low = monitor)
   - Scientific reasons
   - Healthy alternatives

3. RECOMMENDED FOODS (15-25 foods):
   - Specific foods that help manage the condition
   - Foods rich in recommended nutrients
   - Anti-inflammatory foods if applicable

4. MEAL TIMING:
   - Best times to eat
   - Frequency recommendations
   - Fasting considerations

5. PORTION CONTROL:
   - Appropriate portion sizes
   - Caloric considerations

6. EVIDENCE SOURCES:
   - Medical organizations (WHO, ADA, AHA, etc.)
   - Clinical guidelines
   - Recent research

Return ONLY the JSON object, no other text.
"""
        
        return prompt
    
    def _parse_llm_response(self, data: Dict, disease_name: str) -> LLMDiseaseProfile:
        """Parse LLM JSON response into dataclass"""
        
        # Parse nutritional guidelines
        guidelines = [
            NutritionalGuideline(**g) for g in data.get("nutritional_guidelines", [])
        ]
        
        # Parse food restrictions
        restrictions = [
            FoodRestriction(**r) for r in data.get("food_restrictions", [])
        ]
        
        return LLMDiseaseProfile(
            disease_id=data.get("disease_id", disease_name.lower().replace(" ", "_")),
            name=data.get("name", disease_name),
            icd10_codes=data.get("icd10_codes", []),
            category=data.get("category", "general"),
            nutritional_guidelines=guidelines,
            food_restrictions=restrictions,
            recommended_foods=data.get("recommended_foods", []),
            meal_timing=data.get("meal_timing", ""),
            portion_control=data.get("portion_control", ""),
            evidence_sources=data.get("evidence_sources", []),
            last_updated=time.strftime("%Y-%m-%d"),
            llm_model=f"{self.provider}/{self.model}"
        )
    
    def batch_generate_profiles(self, 
                                diseases: List[Dict[str, str]], 
                                delay: float = 1.0,
                                cache_dir: str = "./disease_profiles_cache") -> Dict[str, LLMDiseaseProfile]:
        """
        Generate profiles for multiple diseases with caching
        
        Args:
            diseases: List of dicts with 'name', optional 'icd10', 'category'
            delay: Delay between API calls (rate limiting)
            cache_dir: Directory to cache generated profiles
        
        Returns:
            Dict mapping disease_id to LLMDiseaseProfile
        """
        os.makedirs(cache_dir, exist_ok=True)
        profiles = {}
        
        print(f"\n{'='*80}")
        print(f"BATCH GENERATING {len(diseases)} DISEASE PROFILES")
        print(f"{'='*80}\n")
        
        for i, disease in enumerate(diseases, 1):
            disease_name = disease.get("name")
            disease_id = disease.get("disease_id", disease_name.lower().replace(" ", "_"))
            
            # Check cache first
            cache_file = os.path.join(cache_dir, f"{disease_id}.json")
            if os.path.exists(cache_file):
                print(f"[{i}/{len(diseases)}] Loading {disease_name} from cache...")
                try:
                    with open(cache_file, 'r') as f:
                        cached_data = json.load(f)
                    
                    # Reconstruct profile from cached data
                    profile = self._dict_to_profile(cached_data)
                    profiles[disease_id] = profile
                    continue
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Cache read failed: {e}. Regenerating...")
            
            # Generate new profile
            print(f"[{i}/{len(diseases)}] Generating {disease_name}...")
            
            profile = self.generate_disease_profile(
                disease_name=disease_name,
                icd10_code=disease.get("icd10"),
                category=disease.get("category")
            )
            
            if profile:
                profiles[disease_id] = profile
                
                # Cache the profile
                try:
                    with open(cache_file, 'w') as f:
                        json.dump(self._profile_to_dict(profile), f, indent=2)
                    print(f"  ‚úÖ Cached to {cache_file}")
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Cache write failed: {e}")
            
            # Rate limiting
            if i < len(diseases):
                time.sleep(delay)
        
        print(f"\n{'='*80}")
        print(f"GENERATED {len(profiles)}/{len(diseases)} PROFILES")
        print(f"Total tokens used: {self.total_tokens:,}")
        print(f"{'='*80}\n")
        
        return profiles
    
    def _profile_to_dict(self, profile: LLMDiseaseProfile) -> Dict:
        """Convert profile to dictionary for caching"""
        data = asdict(profile)
        return data
    
    def _dict_to_profile(self, data: Dict) -> LLMDiseaseProfile:
        """Convert cached dictionary to profile"""
        guidelines = [NutritionalGuideline(**g) for g in data["nutritional_guidelines"]]
        restrictions = [FoodRestriction(**r) for r in data["food_restrictions"]]
        
        return LLMDiseaseProfile(
            disease_id=data["disease_id"],
            name=data["name"],
            icd10_codes=data["icd10_codes"],
            category=data["category"],
            nutritional_guidelines=guidelines,
            food_restrictions=restrictions,
            recommended_foods=data["recommended_foods"],
            meal_timing=data["meal_timing"],
            portion_control=data["portion_control"],
            evidence_sources=data["evidence_sources"],
            last_updated=data["last_updated"],
            llm_model=data["llm_model"]
        )
    
    def update_profile(self, disease_id: str, cache_dir: str = "./disease_profiles_cache") -> Optional[LLMDiseaseProfile]:
        """
        Regenerate and update a specific disease profile
        
        Args:
            disease_id: ID of disease to update
            cache_dir: Cache directory
        
        Returns:
            Updated profile or None
        """
        cache_file = os.path.join(cache_dir, f"{disease_id}.json")
        
        if not os.path.exists(cache_file):
            print(f"‚ùå No cached profile found for {disease_id}")
            return None
        
        try:
            with open(cache_file, 'r') as f:
                old_data = json.load(f)
            
            print(f"üîÑ Updating profile: {old_data['name']}")
            
            # Regenerate
            new_profile = self.generate_disease_profile(
                disease_name=old_data['name'],
                icd10_code=old_data['icd10_codes'][0] if old_data['icd10_codes'] else None,
                category=old_data['category']
            )
            
            if new_profile:
                # Update cache
                with open(cache_file, 'w') as f:
                    json.dump(self._profile_to_dict(new_profile), f, indent=2)
                
                print(f"‚úÖ Profile updated: {disease_id}")
                return new_profile
            
        except Exception as e:
            print(f"‚ùå Update failed: {e}")
        
        return None


def test_llm_profile_generation():
    """Test the LLM disease profile generator"""
    
    print("\n" + "="*80)
    print("TESTING LLM DISEASE PROFILE GENERATOR")
    print("="*80)
    
    generator = LLMDiseaseProfileGenerator()
    
    if not generator.client:
        print("\n‚ö†Ô∏è SETUP REQUIRED:")
        print("1. Install: pip install openai")
        print("2. Get API key: https://platform.openai.com/api-keys")
        print("3. Set environment variable: set OPENAI_API_KEY=sk-your-key")
        print("\nüí∞ COST ESTIMATE:")
        print("- ~$0.10-0.30 per disease profile")
        print("- 100 diseases = ~$10-30")
        print("- Profiles are cached to avoid regeneration")
        return
    
    # Test 1: Generate single profile
    print("\nTEST 1: Generate Type 2 Diabetes Profile")
    print("-" * 80)
    
    profile = generator.generate_disease_profile(
        disease_name="Type 2 Diabetes Mellitus",
        icd10_code="E11",
        category="endocrine"
    )
    
    if profile:
        print(f"\n‚úÖ Generated Profile:")
        print(f"   Disease: {profile.name}")
        print(f"   ICD-10: {', '.join(profile.icd10_codes)}")
        print(f"   Category: {profile.category}")
        print(f"   Nutritional Guidelines: {len(profile.nutritional_guidelines)}")
        print(f"   Food Restrictions: {len(profile.food_restrictions)}")
        print(f"   Recommended Foods: {len(profile.recommended_foods)}")
        print(f"   Model: {profile.llm_model}")
        
        print(f"\n   Sample Guidelines:")
        for g in profile.nutritional_guidelines[:3]:
            print(f"     ‚Ä¢ {g.nutrient}: {g.target} {g.unit} (Priority: {g.priority})")
        
        print(f"\n   Sample Restrictions:")
        for r in profile.food_restrictions[:3]:
            print(f"     ‚Ä¢ AVOID {r.food_item} ({r.severity}) - {r.reason}")
        
        print(f"\n   Sample Recommended Foods:")
        print(f"     {', '.join(profile.recommended_foods[:10])}")
        
        print(f"\n   Evidence Sources:")
        for source in profile.evidence_sources:
            print(f"     ‚Ä¢ {source}")
    
    # Test 2: Batch generation with caching
    print("\n\nTEST 2: Batch Generate Common Diseases (with caching)")
    print("-" * 80)
    
    common_diseases = [
        {"name": "Type 2 Diabetes Mellitus", "icd10": "E11", "category": "endocrine"},
        {"name": "Hypertension", "icd10": "I10", "category": "cardiovascular"},
        {"name": "Obesity", "icd10": "E66.9", "category": "endocrine"},
    ]
    
    profiles = generator.batch_generate_profiles(
        diseases=common_diseases,
        delay=2.0,  # 2 second delay between calls
        cache_dir="./disease_profiles_cache"
    )
    
    print(f"\n‚úÖ Generated {len(profiles)} profiles")
    print(f"üí∞ Total tokens used: {generator.total_tokens:,}")
    
    # Test 3: Load from cache
    print("\n\nTEST 3: Load from Cache (no API calls)")
    print("-" * 80)
    
    generator2 = LLMDiseaseProfileGenerator()
    profiles2 = generator2.batch_generate_profiles(
        diseases=common_diseases,
        cache_dir="./disease_profiles_cache"
    )
    
    print(f"‚úÖ Loaded {len(profiles2)} profiles from cache")
    print(f"üí∞ Tokens used: {generator2.total_tokens} (should be 0)")
    
    print("\n" + "="*80)
    print("TESTING COMPLETE")
    print("="*80)


if __name__ == "__main__":
    test_llm_profile_generation()
